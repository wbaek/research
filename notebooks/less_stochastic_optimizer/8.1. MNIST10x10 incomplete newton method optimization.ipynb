{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorpack as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from tensorflow.python.ops import gradients_impl\n",
    "from tensorflow.python.ops import array_ops, tensor_array_ops, control_flow_ops\n",
    "\n",
    "def diagonal_inverse_hessians_highrank(ys, xs, gradients=None, name=\"hessians\", colocate_gradients_with_ops=False,\n",
    "            gate_gradients=False, aggregation_method=None):\n",
    "  \"\"\"Constructs the Hessian (one or more rank matrix) of sum of `ys` with respect to `x` in `xs`.\n",
    "  `hessians_highrank()` adds ops to the graph to output the Hessian matrix of `ys`\n",
    "  with respect to `xs`.  It returns a list of `Tensor` of length `len(xs)`\n",
    "  where each tensor is the Hessian of `sum(ys)`. This function currently\n",
    "  only supports evaluating the Hessian with respect to (a list of) one-\n",
    "  dimensional tensors.\n",
    "  The Hessian is a matrix of second-order partial derivatives of a scalar\n",
    "  tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).\n",
    "  Args:\n",
    "    ys: A `Tensor` or list of tensors to be differentiated.\n",
    "    xs: A `Tensor` or list of tensors to be used for differentiation.\n",
    "    name: Optional name to use for grouping all the gradient ops together.\n",
    "      defaults to 'hessians'.\n",
    "    colocate_gradients_with_ops: See `gradients()` documentation for details.\n",
    "    gate_gradients: See `gradients()` documentation for details.\n",
    "    aggregation_method: See `gradients()` documentation for details.\n",
    "  Returns:\n",
    "    A list of Hessian matrices of `sum(ys)` for each `x` in `xs`.\n",
    "  Raises:\n",
    "    LookupError: if one of the operations between `xs` and `ys` does not\n",
    "      have a registered gradient function.\n",
    "  \"\"\"\n",
    "  xs = gradients_impl._AsList(xs)\n",
    "  kwargs = {\n",
    "    'colocate_gradients_with_ops': colocate_gradients_with_ops,\n",
    "    'gate_gradients': gate_gradients,\n",
    "    'aggregation_method': aggregation_method\n",
    "  }\n",
    "  # Compute first-order derivatives and iterate for each x in xs.\n",
    "  hessians = []\n",
    "  _gradients = tf.gradients(ys, xs, **kwargs) if gradients is None else gradients\n",
    "  for i, _gradient, x in zip(range(len(xs)), _gradients, xs):\n",
    "    shape = x.shape\n",
    "    _gradient = tf.reshape(_gradient, [-1])\n",
    "    \n",
    "    n = tf.size(x)\n",
    "    g = tf.gradients(_gradient, x, **kwargs)[0]\n",
    "    hessian = tf.clip_by_value( 1.0 / tf.reshape(g, [-1]), -1e1, 1e1 )\n",
    "    hessians.append(hessian)\n",
    "  return hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorpack as tp\n",
    "\n",
    "from tensorpack import dataset\n",
    "from tensorpack.dataflow import imgaug, AugmentImageComponent, BatchData, PrefetchData\n",
    "import tensorpack.tfutils.symbolic_functions as symbf\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.training import optimizer\n",
    "\n",
    "class ModelMNIST10x10_simple(object):\n",
    "    def __init__(self, learning_rate=1.0, batch_size=128, momentum=0.9, clip_value=1e2):\n",
    "        self.batch_size = batch_size\n",
    "        self.inputs = [\n",
    "            tf.placeholder(tf.float32, shape=(None, 10, 10, 1)),\n",
    "            tf.placeholder(tf.int32, shape=(None,)),\n",
    "            tf.placeholder(tf.float32, shape=(None, 10))\n",
    "        ]\n",
    "        \n",
    "        self.probability, self.cost, self.accuracy = self._build_graph(self.inputs)\n",
    "        self.op = self._get_optimize_operator(self.cost, learning_rate, momentum)\n",
    "        self.dataflow = {\n",
    "            'train':self._get_data('train'),\n",
    "            'valid':self._get_data('test'),\n",
    "        }\n",
    "        self.clip_value = clip_value\n",
    "        \n",
    "    def _build_graph(self, inputs):\n",
    "        image, label, vector = inputs\n",
    "        \n",
    "        with slim.arg_scope([slim.layers.conv2d], weights_regularizer=slim.l2_regularizer(1e-4), activation_fn=tf.nn.relu), \\\n",
    "             slim.arg_scope([slim.layers.fully_connected], weights_regularizer=slim.l2_regularizer(1e-5)):\n",
    "            l = slim.layers.conv2d(image, 8, [3, 3], padding='SAME', scope='conv0' ) # 10x10\n",
    "            l = slim.layers.max_pool2d(l, [2, 2], scope='pool0') # 5x5\n",
    "            l = slim.layers.conv2d(l, 8, [3, 3], scope='conv1') # 3x3\n",
    "            l = slim.layers.conv2d(l, 8, [3, 3], scope='conv2') # 1x1\n",
    "            l = slim.layers.flatten(l, scope='flatten')\n",
    "            logits = slim.layers.fully_connected(l, 10, activation_fn=None, scope='fc0')\n",
    "\n",
    "        # Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\n",
    "        #cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=label)\n",
    "        cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=vector)\n",
    "        cost = tf.reduce_mean(cost, name='cross_entropy_loss')\n",
    "\n",
    "        prob = tf.nn.softmax(logits, name='prob')\n",
    "        accuracy = symbf.accuracy(logits, label, topk=1)\n",
    "        return prob, cost, accuracy\n",
    "    \n",
    "    def _get_optimize_operator(self, cost, learning_rate=1.0, momentum=0.9):\n",
    "        var_list = (tf.trainable_variables() + tf.get_collection(tf.GraphKeys.TRAINABLE_RESOURCE_VARIABLES))\n",
    "        var_list += tf.get_collection(tf.GraphKeys._STREAMING_MODEL_PORTS)\n",
    "\n",
    "        processors = [optimizer._get_processor(v) for v in var_list]\n",
    "        var_refs = [p.target() for p in processors]\n",
    "\n",
    "        # compute_gradients\n",
    "        grads = tf.gradients(\n",
    "                cost, var_refs,\n",
    "                grad_ys=None, aggregation_method=None, colocate_gradients_with_ops=True)\n",
    "        hessis = diagonal_inverse_hessians_highrank(\n",
    "                 cost, var_refs, gradients=grads,\n",
    "                 aggregation_method=None, colocate_gradients_with_ops=True)\n",
    "        \n",
    "        second_order_grads = []\n",
    "        for g, h in zip(grads, hessis):\n",
    "            shape = g.shape\n",
    "            h_inv = tf.reshape(h, shape)\n",
    "            grad = tf.multiply(h_inv, g)\n",
    "            grad = tf.reshape(grad, shape)\n",
    "            second_order_grads.append(grad)\n",
    "        grads_and_vars = list(zip(second_order_grads, var_list))\n",
    "        \n",
    "        self.grads = grads\n",
    "        \n",
    "        '''\n",
    "        self.global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        lr_schedule = {\n",
    "            'step':     [                   1],\n",
    "            'rate':     [0.1*learning_rate, learning_rate],\n",
    "        }\n",
    "        lr_schedule['step'] = ops.convert_n_to_tensor(lr_schedule['step'], tf.int64)\n",
    "        learning_rate = tf.train.piecewise_constant(self.global_step, lr_schedule['step'], lr_schedule['rate'])\n",
    "        '''\n",
    "        #opt = tf.train.AdamOptimizer(learning_rate)\n",
    "        opt = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "        #opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        return opt.apply_gradients(grads_and_vars)\n",
    "    \n",
    "    def _get_data(self, train_or_test):\n",
    "        BATCH_SIZE = self.batch_size\n",
    "        isTrain = train_or_test == 'train'\n",
    "        ds = dataset.Mnist(train_or_test)\n",
    "        if isTrain:\n",
    "            augmentors = [\n",
    "                #imgaug.RandomApplyAug(imgaug.RandomResize((0.8, 1.2), (0.8, 1.2)), 0.3),\n",
    "                #imgaug.RandomApplyAug(imgaug.RotationAndCropValid(15), 0.5),\n",
    "                #imgaug.RandomApplyAug(imgaug.SaltPepperNoise(white_prob=0.01, black_prob=0.01), 0.25),\n",
    "                imgaug.Resize((10, 10)),\n",
    "                imgaug.CenterPaste((12, 12)),\n",
    "                imgaug.RandomCrop((10, 10)),\n",
    "                imgaug.MapImage(lambda x: x.reshape(10, 10, 1))\n",
    "            ]\n",
    "        else:\n",
    "            augmentors = [\n",
    "                imgaug.Resize((10, 10)),\n",
    "                imgaug.MapImage(lambda x: x.reshape(10, 10, 1))\n",
    "            ]\n",
    "        ds = AugmentImageComponent(ds, augmentors)\n",
    "        ds = BatchData(ds, BATCH_SIZE, remainder=not isTrain)\n",
    "        if isTrain:\n",
    "            ds = PrefetchData(ds, 3, 2)\n",
    "        return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot reshape a tensor with 72 elements to shape [72,72] (5184 elements) for 'Reshape_17' (op: 'Reshape') with input shapes: [72], [2] and with input tensors computed as partial shapes: input[1] = [72,72].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot reshape a tensor with 72 elements to shape [72,72] (5184 elements) for 'Reshape_17' (op: 'Reshape') with input shapes: [72], [2] and with input tensors computed as partial shapes: input[1] = [72,72].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7e4870c11e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelMNIST10x10_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-8996db099af6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, batch_size, momentum, clip_value)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_optimize_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         self.dataflow = {\n\u001b[1;32m     27\u001b[0m             \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8996db099af6>\u001b[0m in \u001b[0;36m_get_optimize_operator\u001b[0;34m(self, cost, learning_rate, momentum)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e2\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mh_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   2617\u001b[0m   \"\"\"\n\u001b[1;32m   2618\u001b[0m   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\n\u001b[0;32m-> 2619\u001b[0;31m                                 name=name)\n\u001b[0m\u001b[1;32m   2620\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot reshape a tensor with 72 elements to shape [72,72] (5184 elements) for 'Reshape_17' (op: 'Reshape') with input shapes: [72], [2] and with input tensors computed as partial shapes: input[1] = [72,72]."
     ]
    }
   ],
   "source": [
    "model = ModelMNIST10x10_simple(learning_rate=0.1, momentum=0.9, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('session initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "history = []\n",
    "for epoch in range(30):\n",
    "    result = {}\n",
    "    \n",
    "    model.dataflow['train'].reset_state()\n",
    "    step, costs, accuracies = 0, [], []\n",
    "    \n",
    "    timestamp = time.time()\n",
    "    for datapoint in model.dataflow['train'].get_data():\n",
    "        datapoint.append( sklearn.preprocessing.label_binarize( datapoint[1], range(10) ).astype(np.float32) )\n",
    "        _, cost, accuracy, grads = sess.run([model.op, model.cost, model.accuracy, model.grads],\n",
    "                                     feed_dict=dict(zip(model.inputs, datapoint)))\n",
    "        grads = [np.sum(np.abs(g)) for g in grads]\n",
    "        costs.append(cost)\n",
    "        accuracies.append(accuracy)\n",
    "        step += 1\n",
    "        #print('[train] epoch:%04d step:%04d cost:%.3f accuracy:%0.3f'%(epoch, step, cost, accuracy))\n",
    "    eplapsed = time.time() - timestamp\n",
    "    print('[%04d] [train] cost:%.3f accuracy:%0.3f elapsed:%.3fs'%(epoch+1, np.mean(costs), np.mean(accuracies), eplapsed), end=' ')\n",
    "    result['train'] = {'epoch':epoch, 'cost':np.mean(costs), 'accuracy':np.mean(accuracies), 'grads_abs':grads}\n",
    "\n",
    "    model.dataflow['valid'].reset_state()\n",
    "    costs, accuracies = [], []\n",
    "    timestamp = time.time()\n",
    "    for datapoint in model.dataflow['valid'].get_data():\n",
    "        datapoint.append( sklearn.preprocessing.label_binarize( datapoint[1], range(10) ).astype(np.float32) )\n",
    "        cost, accuracy = sess.run([model.cost, model.accuracy],\n",
    "                                     feed_dict=dict(zip(model.inputs, datapoint)))\n",
    "        costs.append(cost)\n",
    "        accuracies.append(accuracy)\n",
    "    eplapsed = time.time() - timestamp\n",
    "    print('[valid] cost:%.3f accuracy:%0.3f elapsed:%.3fs'%(np.mean(costs), np.mean(accuracies), eplapsed))\n",
    "    result['valid'] = {'epoch':epoch, 'cost':np.mean(costs), 'accuracy':np.mean(accuracies)}\n",
    "    \n",
    "    history.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4*3))\n",
    "for i, label in enumerate(['cost', 'accuracy', 'grads_abs']):\n",
    "    ax = fig.add_subplot(3, 1, i+1)\n",
    "    ax.set_xlabel('epoch', fontsize=12)\n",
    "    ax.set_ylabel(label, fontsize=12)\n",
    "    ax.set_title(label, fontsize=12)\n",
    "    for j, mode in enumerate(['train', 'valid']):\n",
    "        if not label in history[0][mode]:\n",
    "            continue\n",
    "        ax.plot(np.array([h[mode]['epoch'] for h in history]), np.array([np.sum(h[mode][label]) for h in history]), label=mode)\n",
    "    ax.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
